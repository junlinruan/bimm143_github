---
title: "Class 8: Breast Cancer Mini Project"
author: "Junlin Ruan (PID:A17839687)"
format: pdf
toc: true
---

## Background

The goal of this mini-project is for you to explore a complete analysis using the unsupervised learning techniques covered in class. You’ll extend what you’ve learned by combining PCA as a preprocessing step to clustering using data that consist of measurements of cell nuclei of human breast masses. This expands on our RNA-Seq analysis from last day.

The data itself comes from the Wisconsin Breast Cancer Diagnostic Data Set first reported by K. P. Benne and O. L. Mangasarian: “Robust Linear Programming Discrimination of Two Linearly Inseparable Sets”.

Values in this data set describe characteristics of the cell nuclei present in digitized images of a fine needle aspiration (FNA) of a breast mass.

## Data Import

Data was downloaded from the class website as a CSV file.

```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names=1)
head(wisc.df)
```

## Data Exploration

The first column `diagnosis` is the expert opinion on the sample (i.e. project FNA)

```{r}
head(wisc.df$diagnosis)
```

Remove the diagnosis from data for subsequent analysis
```{r}
wisc.data <- wisc.df[,-1]
dim(wisc.data)
```

Store the diagnosis as a vector for use later when we compare our results to those from experts in the field.

```{r}
diagnosis <- factor(wisc.df$diagnosis)
```

> Q1. How many observations are in this dataset?

There are `r nrow(wisc.data)` observations/patients in the dataset


> Q2. How many of the observations have a malignant diagnosis?

```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
```


```{r}
table(wisc.df$diagnosis)
```

> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
#colnames(wisc.data)
length(grep("_mean", colnames(wisc.data)))
```

## Principal Component Analysis (PCA)

The `prcomp()` function to do PCA has a `scale=FALSE` default. In general, we nearly always want to set this to TRUE so our analysis is not dominated by columns/variables in our dataset that have high standard deviation and mean when compared to others, just because the units of measurement are on different scales.


```{r}
wisc.pr <- prcomp(wisc.data, scale = TRUE)
summary(wisc.pr)
```
> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)? 

```{r}

pv <- (wisc.pr$sdev)^2 / sum((wisc.pr$sdev)^2)

cum_pv <- cumsum(pv)
```

```{r}
pv[1]
```

PC1 = 0.4427, so 44.27% of variance.
> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data? 

```{r}
which(cum_pv >= 0.70)[1]
```
3 PCs >= 70%.

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

```{r}
which(cum_pv >= 0.90)[1]
```
7 PCs are at least 90%.

### PCA Score Plot

The main PC result figure is called a "scare plot" or "PC plot" or "ordination plot"...

```{r}
library(ggplot2)

ggplot(wisc.pr$x) +
  aes(PC1, PC2, col = diagnosis) +
  geom_point()
```

```{r}
biplot(wisc.pr)
```

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

This plot does not show any clear information to me as all the words are blurred together.

```{r}
plot(wisc.pr$x, col = diagnosis , 
     xlab = "PC1", ylab = "PC2")
```
> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

They look similar in overall pattern.
```{r}
plot(wisc.pr$x[, 1], wisc.pr$x[, 3], col = diagnosis, 
     xlab = "PC1", ylab = "PC3")
```


## PCA Scree-plot

A plot of how much variance each PC captures.

```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
pve <- pr.var/sum(pr.var)
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

```{r}
#install.packages("factoextra")
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```


### Communicating the PCA result

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation["concave.points_mean","PC1"]
```

> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
summary(wisc.pr)
```

## Hierarchical clustering

Just clustering the original data is not very informative or helpful.

```{r}
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist)
```

View the clustering dendrogram result
> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust)
abline(h=19, col = "red", lty=2)
```
> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k = 4)
table(wisc.hclust.clusters)
```

```{r}
table(wisc.hclust.clusters, diagnosis)
```
k = 4 is the best as increase nor decrease could result in better clustering.




## Combining methods (PCA and Clustering)

Clustering the original data was not very productive. The PCA results looked promising. Here we combine these methods by clustering from our PCA results. In other words: "clustering in PC space"...

> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

```{r}
## Take the first 3 PCs
dist.pc <- dist(wisc.pr$x[,1:3])
wisc.pr.hclust <- hclust(dist.pc, method = "ward.D2")
```

View the tree...
```{r}
plot(wisc.pr.hclust)
abline(h = 70, col = "red")
```
Ward.D2 method gives the best results

To ger our clustering membership vector (i.e. our main clustering result). We "cut" the tree at a desired height or to yield a desired number of "k" groups.

```{r}
grps <- cutree(wisc.pr.hclust, h = 70)
table(grps)
```

> Q15. How well does the newly created model with four clusters separate out the two diagnoses?

It shows mostly maglinant in cluster 1 and benign in cluster 2.

```{r}
table(grps, diagnosis)
```
> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

They both did decent separations, but post PCA hierarchical did the best with less overlapp and simpler grouping.

>Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

Sensitivity: TP/(TP+FN)
Specificity: TN/(TN+FN)

Before PCA:
sensitivity = (165+5+2) / (165+5+2+40) = 0.811
specificity = 343 / (343 + (12+2+0)) = 0.961
After PCA: 
sensitivity = 188 / (188 + 24) = 0.887
specificity = 329 / (329 + 28) = 0.922

Hierarchical after PCA has better sensitivity but slightly lower spevificity.

## Prediction

We can use our PCA model to predict with new input patient samples.

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Q18. Which of these new patients should we prioritize for follow up based on your results?

We should prioritize cluster 1 patients as they are more likely diagnosis with malignant samples.